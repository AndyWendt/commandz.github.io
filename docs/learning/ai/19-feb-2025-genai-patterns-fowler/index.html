<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fowler &amp; Subramaniam on GenAI patterns - Commandz.io</title>
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <header>
        <nav>
            <a href="/" class="nav-logo">
                <img src="/images/cmdz.jpg" alt="Commandz.io Logo" />
            </a>
            <a href="/about">About</a>
            <a href="/posts">Blog</a>
            <a href="/learning">Learning</a>
            <a href="/snippets">Snippets</a>
        </nav>
    </header>

    <main>
        
<article class="content">
    <header class="content-header">
        <h1 class="title">Fowler &amp; Subramaniam on GenAI patterns</h1>
        
        <div class="metadata">
            <div class="primary-meta">
                
                <time datetime="2025-02-24T00:00:00.000Z">24 Feb 2025</time>
                

                

                
            </div>

            
            <div class="tags-container">
                
                <span class="tag">ai</span>
                
                <span class="tag">llm</span>
                
                <span class="tag">learning</span>
                
            </div>
            
        </div>

        
        <div class="abstract">
            Emerging Patterns in Building GenAI Products
        </div>
        

        
        <div class="featured-image">
            <a href="https://martinfowler.com/articles/gen-ai-patterns/" target="_blank" rel="noopener">
                <img src="/images/blog-article.webp" alt="Fowler &amp; Subramaniam on GenAI patterns">
            </a>
        </div>
        
    </header>

    <div class="content-body">
        <p>The team at ThoughtWorks have distilled several patterns that they've found useful in building GenAI products.  Some of these patterns have emerged from the new range of problems that these tools present: &quot;including hallucination, unbounded data access and non-determinism.&quot;</p>
<h1>Direct prompting</h1>
<p>LLM will not know anything beyond what it was trained or things that happened since.  May not know the context it's operating in and therefore it may not prioritize it's knowledge.</p>
<p>Habits of misleading replies and over confidence.  Hallucinate.</p>
<p>In order to use this pattern you need to figure out how good the results of the prompting is.  Thought works has found that a strong emphasis on a systematic and deliberate testing of AI systems is crucial to allow for changing them in various ways in the future.</p>
<h1>Evals</h1>
<p>Gen AI cannot be evaluated deterministically therefore you must use a scoring engine of some sort.  You can evaluate a model based on individual output however more often you use a range of scenarios.</p>
<p>You can use a few different ways to evaluate a model's outputs: One is to have the model self evaluate. Next is to have another LLM model b the judge. Lastly a human evaluation is also quite useful when you have to see if the model quote unquote gets it.</p>
<p>Generally LOM has judge and combining with human evaluation works the best.  This leverages automated feedback and human feedback as well which is crucial to know if the tone and clarity of the messages correct.</p>
<p>Evals will have to be tested based on a threshold rather than simple pass or fail given that they are non-deterministic.</p>
<p>Indeed it is best to establish a benchmark collecting various data points and charting their variance over time.</p>
<p>Scoring and judging is still an inexact science given that we are still in the early days of this tech. It will continue to evolve and change.</p>
<p>Embeddings</p>
<p>Encoding's capture the meaning of data which allows for better comparisons and relationships.  However they are not ideal for structured or relational data.</p>
<p>Embeddings provide a way to index large quantities of unstructured data.</p>
<h1>Rag</h1>
<p>Rag is an effective tool for use with specialized knowledge bases.  However you have to present it with the correct documents.<br>
One of the best ways to do this is to leverage embeddings.  You need to let it know that it needs to determine when it doesn't have sufficient data. And to also use this data explicitly.</p>
<p>Rag allows you to add data beyond what a model is trained on and beyond the date that it was trained on.  It is great for rapidly changing data.</p>
<p>The contacts provided can help mitigate biases in the original training.</p>
<p>Generally, Rag is much more cost effective than fine tuning.</p>
<p>Chunk retrieval by itself isn't efficient.</p>
<p>&quot;we've found we can tackle most of our generative AI work using Retrieval Augmented Generation (RAG).&quot;</p>
<h2>RAG Limitations</h2>
<h3>Inefficient Retrieval</h3>
<p>&quot;relying solely on document chunk embeddings in a vector store won’t lead to efficient retrieval&quot;</p>
<p>&quot;dense embeddings are good at finding similar paragraphs, they inevitably lose some semantic detail. No amount of fine-tuning can completely bridge this gap.&quot;</p>
<p>Use <a href="https://martinfowler.com/articles/gen-ai-patterns/#hybrid-retriever">Hybrid Retriever</a> to mitigate these issues.</p>
<ul>
<li>
<p><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">term frequency–inverse document frequency</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Okapi_BM25">Okapi BM25</a></p>
</li>
<li>
<p>Using keyword searches with vector search can lead to too many results but you can deal with this by using a reranker</p>
</li>
<li>
<p>Recommends chunks of 1000 characters with 100 characters of overlap with a hybrid retriever</p>
</li>
<li>
<p>OpenAI's <a href="https://openai.com/index/new-embedding-models-and-api-updates">text-embedding-3-large</a> for embeddings</p>
</li>
<li>
<p>Sometimes you don't even need to use vector searches</p>
</li>
</ul>
<h3>Minimalistic User Query</h3>
<p>Oftentimes a User's query might not be specific enough or have enough data. This can lead &quot;to less accurate and more generalized results.&quot;</p>
<p>Use <a href="https://martinfowler.com/articles/gen-ai-patterns/#query-rewrite">Query Rewriting</a> to mitigate. Another option might be providing already formed options for the user.</p>
<ul>
<li>
<p>combine the results</p>
</li>
<li>
<p>crucial for complex searches. Searches can often be improved by using the proper terms.</p>
</li>
<li>
<p>Extra cost associated</p>
</li>
</ul>
<h3>Context bloat</h3>
<p>Currently, LLMs (even LLMs designed for large-context) have issues with large context and will ignore details in the middle of the context.</p>
<p>Use the <a href="https://martinfowler.com/articles/gen-ai-patterns/#reranker">Reranker</a> pattern to mitigate.</p>
<ul>
<li>
<p>works well with an overly large result set</p>
</li>
<li>
<p><a href="https://sbert.net/docs/package_reference/cross_encoder/cross_encoder.html">cross-encoder</a> like <a href="https://huggingface.co/BAAI/bge-reranker-large">bge-reranker-large</a></p>
</li>
<li>
<p>Enhances the accuracy and relevance of documents</p>
</li>
<li>
<p>Useful for incorporating a user's preferences</p>
</li>
<li>
<p>adds cost</p>
</li>
</ul>
<h3>Gullibility</h3>
<p>Over-confidence, hallucinating, revealing secrets, etc.</p>
<p>Use <a href="https://martinfowler.com/articles/gen-ai-patterns/#guardrails">Guardrails</a> pattern..</p>
<ul>
<li>
<p>input and output guardrails</p>
</li>
<li>
<p>generally a specific model</p>
</li>
<li>
<p>can implement the <a href="https://docs.nvidia.com/nemo/guardrails/user_guides/guardrails-library.html#self-check-input">self_check_input</a> rails of <a href="https://docs.nvidia.com/nemo/guardrails/user_guides/guardrails-library.html">NeMo Guardrails</a> framework.</p>
</li>
<li>
<p>can also use embeddings given that they are more flexible than rigid rules</p>
</li>
<li>
<p>used <a href="https://github.com/aurelio-labs/semantic-router">Semantic Router</a> to route or reject</p>
</li>
</ul>
<h1>Fine-tuning</h1>
<blockquote>
<p>Fine tuning a model incurs significant skills, computational resources, expense, and time. Therefore it's wise to try other techniques first, to see if they will satisfy our needs - and in our experience, they usually do.</p>
</blockquote>
<p>Fine-tuning is usually not the best approach given that it's expensive to do.</p>
<p>First try different prompting tweaks. Then Introduce Rag and then finally Fine Tuning.</p>
<p>RAG might not be enough and might not supply enough context or too narrow.</p>
<p>&quot;backpropagation, where errors are propagated backward through the model to update its weights, improving future predictions.&quot;</p>
<p>Full fine-tuning every part of the model is affected.</p>
<p>Using Selective layer fine-tuning, you can achieve significant improvements by selectively fine-tuning specific layers.</p>
<p>Parameter-Efficient Fine-Tuning (PEFT) adds and trains new params using <a href="https://arxiv.org/abs/2106.09685"><strong>Low-Rank Adaptation (LoRA)</strong></a> or <a href="https://arxiv.org/abs/2104.08691"><strong>Prompt Tuning</strong></a></p>
<p>without changing the base model's parameters.</p>
<p>The majority of your efforts will go into data preparation and curation. Look at synthetic data generation.</p>

    </div>
</article>

<style>
    .content {
        max-width: 900px;
        margin: 0 auto;
        padding: 0 1rem;
    }

    .content-header {
        margin-bottom: 3rem;
    }

    .title {
        font-size: 2.5rem;
        margin-bottom: 1rem;
        line-height: 1.2;
    }

    .metadata {
        margin: 1.5rem 0;
    }

    .primary-meta {
        color: #666;
        font-size: 1rem;
        margin-bottom: 1rem;
    }

    .separator {
        margin: 0 0.5rem;
        color: #ccc;
    }

    .tags-container {
        display: flex;
        flex-wrap: wrap;
        gap: 0.5rem;
        margin-top: 0.75rem;
    }

    .tag {
        background-color: #f3f4f6;
        color: #4b5563;
        font-size: 0.875rem;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        display: inline-block;
        transition: all 0.2s ease;
    }

    .tag:hover {
        background-color: #e5e7eb;
    }

    .abstract {
        font-size: 1.25rem;
        color: #4b5563;
        margin: 2rem 0;
        line-height: 1.6;
        font-style: italic;
    }

    .featured-image {
        margin: 2rem auto;
        text-align: center;
        max-width: 700px;
    }

    .featured-image img {
        max-width: 100%;
        height: auto;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
    }

    /* Specific image sizing based on image path */
    img[src*="/books/"] {
        max-width: 300px;
    }

    img[src*="/courses/"] {
        max-width: 500px;
    }

    img[src*="/videos/"] {
        max-width: 600px;
    }

    .content-body {
        font-size: 1.125rem;
        line-height: 1.75;
        color: #1a1a1a;
    }

    @media (max-width: 768px) {
        .title {
            font-size: 2rem;
        }

        .abstract {
            font-size: 1.125rem;
        }

        .featured-image {
            max-width: 100%;
        }
        
        img[src*="/books/"],
        img[src*="/courses/"],
        img[src*="/videos/"] {
            max-width: 100%;
            width: auto;
        }
    }
</style> 

    </main>

    <footer class="site-footer">
        <p>&copy; 2025 Commandz.io. All rights reserved.</p>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html> 