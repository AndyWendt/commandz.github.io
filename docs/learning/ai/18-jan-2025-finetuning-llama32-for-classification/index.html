<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Experiments in Fine-tuning Llama 3.2 for classification using Lora - Commandz.io</title>
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <header>
        <nav>
            <a href="/" class="nav-logo">
                <img src="/images/cmdz.jpg" alt="Commandz.io Logo" />
            </a>
            <a href="/about">About</a>
            <a href="/posts">Blog</a>
            <a href="/learning">Learning</a>
            <a href="/snippets">Snippets</a>
        </nav>
    </header>

    <main>
        
<article class="content">
    <header class="content-header">
        <h1 class="title">Experiments in Fine-tuning Llama 3.2 for classification using Lora</h1>
        
        <div class="metadata">
            <div class="primary-meta">
                
                <time datetime="2025-01-15T00:00:00.000Z">15 Jan 2025</time>
                

                

                
            </div>

            
            <div class="tags-container">
                
                <span class="tag">ai</span>
                
                <span class="tag">fine-tuning</span>
                
                <span class="tag">lora</span>
                
                <span class="tag">llama</span>
                
                <span class="tag">learning</span>
                
            </div>
            
        </div>

        
        <div class="abstract">
            An experiment on using Lora to fine-tune Llama 3.2 to specialize a model for classifying support requests
        </div>
        

        
        <div class="featured-image">
            <a href="https://youtu.be/8N9L-XK1eEU" target="_blank" rel="noopener">
                <img src="/images/youtube.png" alt="Experiments in Fine-tuning Llama 3.2 for classification using Lora">
            </a>
        </div>
        
    </header>

    <div class="content-body">
        <p>I started out wanting to play around with fine-tuning Llama 3.2 to see if I could specialize it's capabilities for classifying support requests.</p>
<p>After diving in fairly deep, writing a fair amount of code, and researching a few alternative approaches I would not try this method first nor would I continue with this approach further before investigating alternatives first.</p>
<p>For starters, Meta provides a way and <a href="https://www.llama.com/docs/how-to-guides/fine-tuning/">documentation</a> to fine-tune their Llama models.  They include documentation on full fine-tuning of the model parameters but also PEFT (Parameter Efficient Fine-Tuning) using <a href="https://github.com/microsoft/LoRA">LoRa</a>/QLoRa.  (Keep in mind that you will likely have to request access to LLama models on HuggingFace in order to train using these methods.)  LoRA is particularly ingenious in that it allows you to more efficiently train a model and get a much smaller &quot;adaptation&quot; of that base model than a full re-training of all its parameters.</p>
<p>Using Meta's prebuilt tools would undoubtedly lead to better results faster than writing your own tool once you figure out how to use it.</p>
<p>However, there are alternative, and likely less costly, approaches out there for classification tasks.  One being <a href="https://docs.anthropic.com/en/docs/about-claude/use-case-guides/ticket-routing#use-vector-databases-and-similarity-search-retrieval-to-handle-highly-variable-tickets">the use of a vector database to look up sample classifications from a database of examples</a>.  This is particularly useful when there are too many examples or variations to provide in the context and you only want to provide relevant ones.</p>
<p>If I were to attempt to implement a classification mechanism that is more complex than determining if something is spam/not spam, then I would go down the route of using a vector database of examples and basing the classification off of that.  I believe the results for most tasks will be acceptable and the cost for the implementation will be much lower.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> AutoTokenizer
<span class="token keyword">from</span> peft <span class="token keyword">import</span> get_peft_model<span class="token punctuation">,</span> LoraConfig<span class="token punctuation">,</span> TaskType<span class="token punctuation">,</span> PeftModel
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> Dataset
<span class="token keyword">import</span> json
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os

<span class="token keyword">def</span> <span class="token function">model_name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">"unsloth/Llama-3.2-1B"</span>

<span class="token keyword">def</span> <span class="token function">compute_engine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>

<span class="token keyword">class</span> <span class="token class-name">JsonFile</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> json_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>file_path<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>json_data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">load</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>file_path<span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            <span class="token keyword">return</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">file_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        current_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Labels</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">instance</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> json_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        unique_labels <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'tag'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> json_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        json_file <span class="token operator">=</span> JsonFile<span class="token punctuation">(</span><span class="token punctuation">)</span>
        label2id <span class="token operator">=</span> <span class="token punctuation">{</span>label<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>unique_labels<span class="token punctuation">)</span><span class="token punctuation">}</span>
        id2label <span class="token operator">=</span> <span class="token punctuation">{</span>i<span class="token punctuation">:</span> label <span class="token keyword">for</span> label<span class="token punctuation">,</span> i <span class="token keyword">in</span> label2id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

        instance <span class="token operator">=</span> cls<span class="token punctuation">(</span>json_file<span class="token punctuation">,</span> label2id<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span>
        instance<span class="token punctuation">.</span>persist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> instance

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_files</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>
        json_file <span class="token operator">=</span> JsonFile<span class="token punctuation">(</span><span class="token punctuation">)</span>
        label2id <span class="token operator">=</span> json_file<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'label2id.json'</span><span class="token punctuation">)</span>
        id2label <span class="token operator">=</span> json_file<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'id2label.json'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>json_file<span class="token punctuation">,</span> label2id<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> json_file<span class="token punctuation">,</span> label2id<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>label2id <span class="token operator">=</span> label2id
        self<span class="token punctuation">.</span>id2label <span class="token operator">=</span> id2label
        self<span class="token punctuation">.</span>json_file <span class="token operator">=</span> json_file
        self<span class="token punctuation">.</span>count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>label2id<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Label mapping:"</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label2id<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Label mapping (reverse):"</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>id2label<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">persist</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>json_file<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'label2id.json'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>label2id<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>json_file<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'id2label.json'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>id2label<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">id_from_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>label2id<span class="token punctuation">[</span>label<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">label_from_id</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>id2label<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">)</span><span class="token punctuation">]</span>


<span class="token keyword">class</span> <span class="token class-name">JsonDataset</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">instance</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>
        json_file <span class="token operator">=</span> JsonFile<span class="token punctuation">(</span><span class="token punctuation">)</span>
        data <span class="token operator">=</span> json_file<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'customer_service_dataset.json'</span><span class="token punctuation">)</span>
        labels <span class="token operator">=</span> Labels<span class="token punctuation">.</span>instance<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>data<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels

    <span class="token keyword">def</span> <span class="token function">prepare</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> Dataset<span class="token punctuation">.</span>from_dict<span class="token punctuation">(</span><span class="token punctuation">{</span>
            <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token string">'question'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> self<span class="token punctuation">.</span>data<span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">.</span>id_from_label<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'tag'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> self<span class="token punctuation">.</span>data<span class="token punctuation">]</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Collator</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device

    <span class="token keyword">def</span> <span class="token function">collate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        texts <span class="token operator">=</span> <span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> batch<span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> batch<span class="token punctuation">]</span>

        <span class="token comment"># Tokenize with proper padding</span>
        inputs <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">(</span>
            texts<span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
            max_length<span class="token operator">=</span><span class="token number">512</span>  <span class="token comment"># Add reasonable max length</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">{</span>
            <span class="token string">'input_ids'</span><span class="token punctuation">:</span> inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> inputs<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'labels'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>

<span class="token keyword">class</span> <span class="token class-name">TokenizerFactory</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">create</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> full_model_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> model_name<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>full_model_name<span class="token punctuation">)</span>
        <span class="token keyword">if</span> tokenizer<span class="token punctuation">.</span>pad_token <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
            tokenizer<span class="token punctuation">.</span>padding_side <span class="token operator">=</span> <span class="token string">"right"</span>  <span class="token comment"># Ensure right padding</span>
        <span class="token keyword">return</span> tokenizer

<span class="token keyword">class</span> <span class="token class-name">ModelFactory</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">create</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> full_model_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> model_name<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> compute_engine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tokenizer <span class="token operator">=</span> TokenizerFactory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># Load base model with padding token configuration</span>
        model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            full_model_name<span class="token punctuation">,</span>
            num_labels<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span>  <span class="token comment"># Number of customer service categories</span>
            pad_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        <span class="token comment"># Ensure model knows about padding token</span>
        model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>pad_token_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>pad_token_id
        model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>padding_side <span class="token operator">=</span> <span class="token string">"right"</span>

        <span class="token comment"># Initialize LoRA config with correct target modules for Llama</span>
        lora_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
            r<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
            lora_alpha<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
            target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"q_proj"</span><span class="token punctuation">,</span> <span class="token string">"v_proj"</span><span class="token punctuation">,</span> <span class="token string">"k_proj"</span><span class="token punctuation">,</span> <span class="token string">"o_proj"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># Updated for Llama</span>
            lora_dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
            bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
            task_type<span class="token operator">=</span>TaskType<span class="token punctuation">.</span>SEQ_CLS
        <span class="token punctuation">)</span>

        <span class="token comment"># Apply LoRA</span>
        model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> lora_config<span class="token punctuation">)</span>
        <span class="token keyword">return</span> model


<span class="token keyword">class</span> <span class="token class-name">SimpleFineTuner</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">create</span><span class="token punctuation">(</span>
        cls<span class="token punctuation">,</span>
        device <span class="token operator">=</span> compute_engine<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        tokenizer <span class="token operator">=</span> TokenizerFactory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>
        model <span class="token operator">=</span> ModelFactory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>
        collator <span class="token operator">=</span> Collator<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
        json_file <span class="token operator">=</span> JsonFile<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> device<span class="token punctuation">,</span> collator<span class="token punctuation">,</span> json_file<span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        model<span class="token punctuation">,</span>
        tokenizer<span class="token punctuation">,</span>
        device<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
        collator<span class="token punctuation">,</span>
        json_file
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>train_loader <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device
        self<span class="token punctuation">.</span>collator <span class="token operator">=</span> collator
        self<span class="token punctuation">.</span>json_file <span class="token operator">=</span> json_file

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        dataset<span class="token punctuation">:</span> Dataset<span class="token punctuation">,</span>
        num_epochs<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            total_loss <span class="token operator">=</span> <span class="token number">0</span>
            progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_train_loader<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
            
            <span class="token keyword">for</span> batch <span class="token keyword">in</span> progress_bar<span class="token punctuation">:</span>
                total_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_process_batch<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> progress_bar<span class="token punctuation">,</span> total_loss<span class="token punctuation">)</span>

            avg_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_train_loader<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">, Average Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>self<span class="token punctuation">.</span>json_file<span class="token punctuation">.</span>file_path<span class="token punctuation">(</span><span class="token string">'customer_service_lora_weights'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_process_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> progress_bar<span class="token punctuation">,</span> total_loss<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Forward pass</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>
            input_ids<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            attention_mask<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            labels<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Backward pass</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'loss'</span><span class="token punctuation">:</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> total_loss

    <span class="token keyword">def</span> <span class="token function">_train_loader</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>train_loader <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>
                dataset<span class="token punctuation">,</span>
                batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
                shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                collate_fn<span class="token operator">=</span>self<span class="token punctuation">.</span>collator<span class="token punctuation">.</span>collate
            <span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>train_loader

    <span class="token keyword">def</span> <span class="token function">_optimizer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>optimizer <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            learning_rate<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">2e-4</span>
            self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>optimizer

<span class="token keyword">class</span> <span class="token class-name">LabelPredictor</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">instance</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Load a saved model and label mappings"""</span>
        model_path <span class="token operator">=</span> JsonFile<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>file_path<span class="token punctuation">(</span><span class="token string">'customer_service_lora_weights'</span><span class="token punctuation">)</span>
        tokenizer <span class="token operator">=</span> TokenizerFactory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>

        model <span class="token operator">=</span> PeftModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            ModelFactory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            model_path<span class="token punctuation">,</span>
            is_trainable<span class="token operator">=</span><span class="token boolean">False</span>
        <span class="token punctuation">)</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        labels <span class="token operator">=</span> Labels<span class="token punctuation">.</span>from_files<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> device<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> compute_engine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> tokenizer
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        inputs <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">(</span>
            text<span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            truncation<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

        <span class="token comment"># Get prediction</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
            predicted_class <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> predicted_class<span class="token punctuation">,</span> self<span class="token punctuation">.</span>labels<span class="token punctuation">.</span>label_from_id<span class="token punctuation">(</span>predicted_class<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">run_predict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    label_predictor <span class="token operator">=</span> LabelPredictor<span class="token punctuation">.</span>instance<span class="token punctuation">(</span><span class="token punctuation">)</span>
    class_id<span class="token punctuation">,</span> label <span class="token operator">=</span> label_predictor<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>args<span class="token punctuation">.</span>predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Input text:"</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prediction: </span><span class="token interpolation"><span class="token punctuation">{</span>label<span class="token punctuation">}</span></span><span class="token string"> (class ID: </span><span class="token interpolation"><span class="token punctuation">{</span>class_id<span class="token punctuation">}</span></span><span class="token string">)"</span></span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">run_train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    dataset <span class="token operator">=</span> JsonDataset<span class="token punctuation">.</span>instance<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prepare<span class="token punctuation">(</span><span class="token punctuation">)</span>
    SimpleFineTuner<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>train<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Customer Service Simple Fine Tuner"</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--train'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Train the model'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--predict'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Input for prediction or training dataset'</span><span class="token punctuation">,</span> required<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> args<span class="token punctuation">.</span>train<span class="token punctuation">:</span>
        run_train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> args<span class="token punctuation">.</span>predict <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Please provide an input for prediction"</span><span class="token punctuation">)</span>

        run_predict<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>

    </div>
</article>

<style>
    .content {
        max-width: 900px;
        margin: 0 auto;
        padding: 0 1rem;
    }

    .content-header {
        margin-bottom: 3rem;
    }

    .title {
        font-size: 2.5rem;
        margin-bottom: 1rem;
        line-height: 1.2;
    }

    .metadata {
        margin: 1.5rem 0;
    }

    .primary-meta {
        color: #666;
        font-size: 1rem;
        margin-bottom: 1rem;
    }

    .separator {
        margin: 0 0.5rem;
        color: #ccc;
    }

    .tags-container {
        display: flex;
        flex-wrap: wrap;
        gap: 0.5rem;
        margin-top: 0.75rem;
    }

    .tag {
        background-color: #f3f4f6;
        color: #4b5563;
        font-size: 0.875rem;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        display: inline-block;
        transition: all 0.2s ease;
    }

    .tag:hover {
        background-color: #e5e7eb;
    }

    .abstract {
        font-size: 1.25rem;
        color: #4b5563;
        margin: 2rem 0;
        line-height: 1.6;
        font-style: italic;
    }

    .featured-image {
        margin: 2rem auto;
        text-align: center;
        max-width: 700px;
    }

    .featured-image img {
        max-width: 100%;
        height: auto;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
    }

    /* Specific image sizing based on image path */
    img[src*="/books/"] {
        max-width: 300px;
    }

    img[src*="/courses/"] {
        max-width: 500px;
    }

    img[src*="/videos/"] {
        max-width: 600px;
    }

    .content-body {
        font-size: 1.125rem;
        line-height: 1.75;
        color: #1a1a1a;
    }

    @media (max-width: 768px) {
        .title {
            font-size: 2rem;
        }

        .abstract {
            font-size: 1.125rem;
        }

        .featured-image {
            max-width: 100%;
        }
        
        img[src*="/books/"],
        img[src*="/courses/"],
        img[src*="/videos/"] {
            max-width: 100%;
            width: auto;
        }
    }
</style> 

    </main>

    <footer class="site-footer">
        <p>&copy; 2025 Commandz.io. All rights reserved.</p>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html> 